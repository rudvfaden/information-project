\RequirePackage[l2tabu, orthodox]{nag} 					% Checks for obsolete syntax and package % Layout
\documentclass[10pt,a4paper]{article}

%% font
%\usepackage{MnSymbol}
%\usepackage[mathlf,textlf,minionint,smallfamily]{MinionPro} % must have Minion pro installed Palationo is similar
\usepackage{mathpazo} % add possibly `sc` and `osf` optionsl
\usepackage{eulervm}

%% Author
\def\myaffiliation{University of Copenhagen}
\def\myauthor{Rud Faden}
\def\myemail{rud.faden@econ.ku.dk}
\def\mytitle{Physician Information Acquisition In a Dynamic Setting}
\def\mykeywords{bla, bla bla}

%% packages
\usepackage{faden}
\usetikzlibrary{decorations.pathreplacing}
\graphicspath{{../fig/}}
\usepackage{commath}

%% biblatex path
\addbibresource[datatype=bibtex]{../../bib/library.bib}
\makeindex

% Author and title
\title{\mytitle}
\author{
{\myauthor} \\
\textit{\small \myaffiliation} \\
\small{\texttt{\href{\myemail}{\myemail}}}
}
\date{\today} % no date

\begin{document}

\maketitle

%%--------------------------------------------------------------------------
%% Abstract
%%--------------------------------------------------------------------------
\begin{abstract}
In this project, I examine provider and patient demand for information in a dynamic model where the diagnostic precision is assumed to be related to physician effort, and effort is non-contractible. In each period where the patient and physician interact, the physician gathers information about the patient, and the diagnostic precision is increased. Therefore, optimal physician effort decreases as the physician and patient tie increases. As the physician is unobserved, the insurer compensates the physician by the average effort in the physician population and physician will not provide an optimal level of diagnostic precision in the in the first encounters with a new patient. Therefore the switching cost of the patient increases as the tie with the physician lengthens. This model explains (i) why the cost is negatively related with patient, physician ties and (ii) also introduces the concept of an ``information trap'', where competition is deceasing in the patient physician tie as switching cost increases. Increases.
\end{abstract}
%%--------------------------------------------------------------------------
%% Introduction
%%--------------------------------------------------------------------------
\section{Introduction}
It is a popular view among doctors that long term relationship between doctor and patient is a vital to good primary health care and promote patient satisfaction, and cost-effectiveness. Long term relationships are thought to increase in value because
\begin{quotation}
the practitioners come to know patients over time, and patients come to know the practitioners. The benefits of this knowledge [can] be expected to accrue in a variety of ways. For example, patients should make fewer visits be- cause many problems can be managed on the phone. Fewer hospitalizations should also result, since practitioners are more likely to be able to ascertain whether or not the problem [can] be managed at home \parencite[p. 41--42]{Starfield1992}.
\end{quotation}
and
\begin{quotation}
it \ldots \ takes time for physicians to understand and empathize with patients' values and feelings and to be able to help patients identify and utilize health care services that are appropriate for their condition and life situation\ldots Decisions to adopt healthy habits, to stop smoking to spare a child from passive smoke \ldots are more likely to be made if recommended by a trusted physician in the context of an ongoing relationship \parencite[p. 324--235]{Emanuel1995}.\todo{find more recent quotation}
\end{quotation}
This has to some degree been backed by empirical evidence. Using insurance data \textcite{Weiss1996} find that long-term relations are associated with more preventive care, less hospitalization, and lower costs. However \citeauthor{Weiss1996} does not attempt to separate matching effects from the patient tie effect, which makes the results hard to interpret. In another study on the physician knowledge about his patient,   \textcite{Hjortdahl1991}  finds that physicians with more knowledge about a patient is less likely to order lab tests, more likely to adopt a ``wait-and-see'' approach, and more likely to prescribe drugs and refer patients to specialists.

Despite this evidence, models that incorporate physician knowledge about their patients are scares, and no models exists which describes how physician knowledge is obtained.

In my model, information about a patient is seen as an economics good, which can be produced at a price by the physician. Further it attempts to describe the process of how information is accumulated by the physician and how this may both decrease cost and competition among physicians at the same time.

Very general models of learning have been developed by \textcite{Grossman1977}. However such a model quickly becomes very complex and as a results applications are not easy. Instead I limit myself to a class of monotone decision problems, which greatly simplifies the analysis.
%%--------------------------------------------------------------------------
%% Section: The Patients Utility}
%%--------------------------------------------------------------------------

\section{The Patients Utility}

Following \citet{Rochaix1989}, the patient has a utility function
\[
	U = u(t,s):\, T\times S\longrightarrow\mathbb{R}
\]
where \(t\) is treatment, \(s\) is disease variable classified by its severity of illness, where both \(t\) and \(s\) traverse a real line. It is assumed that the utility function has both increasing and decreasing parts to capture the negative effects of both under and over treatment. It is further assumed that the dis-utility of moving away from the optimum is increasing in \(s\)  such that the patient is more \emph{risk-sensitive} for higher values of \(s\)

%========== DEFINITION: Risk-sensitivity ==========%
\begin{definition}\label{def:risk-sensitivity}
Assuming that the decision problem has a unique solution \(t^{*}(s)\)  and for \(s'>s\),  \(u(t^{*}(s),s)=u(t^{*}(s'),s')\). Then for \(t^{*}(s)>t_{1}\), \(t^{*}(s')>t_{2}\),  \(t_{2}\ge t_{1}\), and \(t^{*}(s')-t_{2}=t^{*}(s)-t_{1}=\Delta t\) the \emph{risk-sensitivity} is monotonically increasing in \(s\)  if
\[
	0\le u(t^{*}(s),s)-u(t_{1},s)\le u(t^{*}(s'),s')-u(t_{2},s')\label{eq:risk-sensitivity}
\]
for all \(s\) and \(t\)  and I write that \(u(t_{1},s)\preceq u(t_{2},s')\)
\end{definition}
%==================================================%

The notion of \emph{risk-sensitivity} is illustrated in \cref{fig:The-patients-utility}.

%========== THEOREM: Single crossing property ==========%
\begin{theorem}\label{thm:single-crossing}
If the risk sensitivity is increasing in \(s\)  then for \(s'>s\), \(u(t,s)\) has a single crossing property in \((s,t)\)
\end{theorem}
%==================================================%

%========== PROF - crossing property ==========%
\begin{proof}
Let \(t'=t^{*}(s')\) and \(t=t^{*}(s)\). Given \cref{def:risk-sensitivity}, it is clear that \(t'\ge t_{2}>t\ge t_{1}\). Therefore I can rewrite \cref{eq:risk-sensitivity} as
\begin{align}
  u(t',s')-u(t_{2},s')\ge u(t,s)-u(t_{1},s)\ge0\label{eq:increasing-differences}
\end{align}
\cref{eq:increasing-differences} clearly have increasing differences in \(s\) and thereby satisfies the single crossing property.
\end{proof}
%==================================================%

The intuition behind \cref{thm:single-crossing}, is that the marginal change \(u(t',\cdot)-u(t,\cdot)\) is larger, when \(s\) is larger. When \(u(t,s)\) is differentiable and concave as in \cref{fig:The-patients-utility}, one might note \(\partial u(t,s)/\partial t\ge0\) for \(t\le t^{*}(s)\) and that for \(\partial u(t,s)/\partial t\le0\) for \(t\ge t^{*}(s)\). Thereby \(\partial u(t,s')/\partial t>\partial u(t,s)/\partial t\) for \(t\le t^{*}(s)\) and \(\partial u(t,s')/\partial t<\partial u(t,s)/\partial t\) for \(t\ge t^{*}(s)\). One might also note that \(\partial u(t,s')/\partial t\) crosses \(\partial u(t,s)/\partial t\) at most once, and only from below.

%========== FIGURE: Utility and single-crossing ==========%
\begin{figure}
     \centering
    \begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{patient-utility.pdf}
	\end{subfigure}
    \begin{subfigure}[b]{0.49\textwidth}
		\includegraphics[width=\textwidth]{single-crossing-property.pdf}
	\end{subfigure}
\caption{\label{fig:The-patients-utility}The patients utility functions. If for the same change in \(t\) the loss in utility is smaller for \(s\) than for \(s'\)  when \(s<s'\)  then I says that risk sensitivity is increasing in \(s\) }
\end{figure}
%=======================================================%

%========== PROPOSITION: Single-crossing property ==========%
\begin{proposition}
Given that \(u(t',s)-u(t,s)\) has a single crossing propositionerty in \(s\) and that both \(S\) and \(T\) are well ordered sets (in the strong set order)\footnote{If \(X' \geq X\) in the strong set order, then \(\max (x',x)\in X'\) and \(\min (x',x)\in X\). E.g. \([2,5]\geq[0,3]\) in the strong set order, while \(\{2,5\} \) and \(\{0,3\}\) is not. \\
	\includegraphics[width=0.4\textwidth]{strong-set-order.pdf}
}, then
\[
	t^{*}(s)=\argmax_{s\in S}u(t,s)\label{eq:increasing-solution}
\]
is increasing in \(s\).\footnote{It should be noted that the assumption of quasi-supermodularity is not needed as the choice space is well ordered (e.i.\ a chain).}
\end{proposition}

\begin{proof}
As both \(T\) and \(S\) are real lines, then it follows trivially that they are well ordered. For the rest of the proof see \textcite{Milgrom1994} or \cref{app:topiks-proof}
\end{proof}
%===========================================%

%========== EXAMPLE: Single-crossing ==========%
\begin{example}
A function with the properties defined in \cref{thm:single-crossing} and \cref{eq:risk-sensitivity} and have the form as in \cref{fig:The-patients-utility} is
\[
	u(t,s) = c-s{(s-t)}^{2}\label{eq:utility-example}
\]
where \(t,s\in\mathbb{R}^{+}\). Assuming that \cref{eq:utility-example} is continuous and twice differential in \(t,s\)  the derivative \(\partial^{2}u(t,s)\big/\partial t\partial s=2s^{2}\ge0\) and \cref{eq:utility-example} has increasing differences and thereby also a single crossing property in \((t,s)\)
\end{example}
%============================================%

%%--------------------------------------------------------------------------
%% Section: Uncertainty with perfect agency
%%--------------------------------------------------------------------------

\section{Uncertainty with perfect agency}

In reality however, \(s\) is never observed. The level of severity for the patients is a random variable represented by \(S\)  characterized by a subjective CDF.\@ \(F(s)\)  with density \(f(s)\)  where \(s\) is a realization of \(S\). The expected value of choosing an admissible treatment intensity \(t\) is given by
\[
	U(t,S)=E[u(t,s)]=\max_{t}\int_{S}u(t,s)\dif F(s)\label{eq:expected-utility-prior}
\]
It is however possible to acquire costly information about \(s\) through medical diagnostics and physician effort. However, for two experiment \(X,Y\) on \(S\)  it is not a priori certain that one experiment \(X\) is necessary more \emph{informative} about \(s\) than the experiment \(Y\)  where \emph{informative} is to be understood in the way the posterior decision induced by the experiment \(X\) insures greater expected utility than the decision induced by the experiment \(Y\). Therefore we must introduce an order of information.

%%--------------------------------------------------------------------------
%% Section: Information ordering
%%--------------------------------------------------------------------------

\subsection{Information ordering}

%========== DEFINITION: affiliation ==========%
\begin{definition}\label{def:afflilation} \parencite{Milgrom1982}
For a family of density functions, let \(x\lor s\) denote the component wise maximum and \(x\land s\) the component wise minimum. Then \(x\) and \(s\) are affiliated if for all \(s\) and \(x\)
\[
	f(s\lor x)\, f(s\land x)\ge f(s)\, f(x)
\]
\end{definition}
%=============================================%

Affiliation of two random variables are equivalent to the monotone likelihood ratio property, and the intuition behind \cref{def:afflilation} is that higher signal realization of \(x\) makes the probability that \(s\) is large, higher. Similarly small signal realization of \(x\) makes the probability of a small \(s\) more likely.\footnote{See \cref{app:affiliation} for more details}

\textcite{Athey2002}  shows that solution given in \cref{eq:increasing-solution} is robust to uncertainty, such that
\[
	t^*(x)=\argmax_{x\in X}\int_Su(t,s)\dif G^\eta(s\mid x)
\]
is increasing in \(x\)  whenever \(x\) and \(s\) are affiliated.\footnote{Note that here we, unlike in \cref{thm:informative}, consider the problem of deciding a treatment \(t\) before the state \(s\) is know, but \emph{after} observing the signal \(x\) }

%========== DEFINITION: Accuracy ==========%
\begin{definition}\label{def:accuracy}
\parencite{Persico2000} Given two signals (experiments) \(X^{\eta}\) and \(X^{\eta'}\),  \(X^{\eta'}\) is more accurate than \(X^{\eta}\) if
\begin{align}
    	T_{\eta,s}(x)=F^{\eta'^{-1}}(F^{\eta}(x\mid s)\mid s)\label{eq:acuracy tranformation}
\end{align}
is non decreasing in \(s\) for all \(x\).\footnote{Note that \cref{eq:acuracy tranformation} can also be written as \(F^{\eta'}(T_{\eta,s}(x)\mid s)=F^{\eta}(x\mid s)\)} Let \(E\) be a real line. A family of signals \(\left \{ X^{\eta}\right \} _{\eta\in E}\), with support \(X:=\bigcup_{x\in E}X^\eta\), is accuracy ordered (A-ordered) if a signal with higher index is more accurate than a signal with lower index.
\end{definition}
%================================================%

To understand the concept of accuracy, it can be noted that
\[
	T_{\eta,s}(X^{\eta}\mid s)\sim X^{\eta'}\mid s
\]
Thus a more accurate signal can be obtained from a less accurate signal, by the transformation \(T_{\eta,s}(X)\)  For a better understanding of the accuracy concept, see \cref{ex:t-transformation-1,ex:t-transformation-2}.

%========== EXAMPLE: T-transformation 1 ==========%
\begin{example}\label{ex:t-transformation-1}
Let  \(\eta\in[0,\infty]\) and let \(S\) be distributed according to any CDF and let \(X_{\eta}\sim\mathbb{U}(s-1/\eta,s+1/\eta)\) and let \(f(x\mid s)=\eta\big /2\) on \(X^\eta\). Then for \(\eta'>\eta\)
\[
	\frac{\eta'}{2}=\frac{\eta}{2}\left(T_{\eta,s}^{-1}(x)\right)'\Leftrightarrow T_{\eta,s}(x)=\frac{\eta}{\eta'}(x-s)+s
\]
To see why, note that

\begin{align*}
	T^{-1}_{\eta,s}(x)               &=\frac{\eta'+\eta s-s}{\eta} \Rightarrow \\
	\left(T^{-1}_{\eta,s}(x)\right)' &=\frac{\eta'}{\eta}
\end{align*}

\begin{figure}
	\includegraphics[width=\textwidth]{t-transformation.pdf}
	\caption{\label{fig:t-transformation}The \(T_{\eta,s}(x)\) transformation}
\end{figure}

Further, one might also note that \(T_{\eta,s}(x)\) is an increasing function by taking the derivative
\[
	\frac{\partial^2}{\partial \eta'\partial s}T_{\eta,s}(x)=\frac{\eta}{\eta'^2}>0
\]
Thus, \(T_{\eta,s}(x)\) transforms \(X^{\eta}\) into \(X^{\eta'}\) when \(T_{\eta,s}(x)\) is increasing~\citep{Persico1996}.

From \cref{fig:t-transformation}, the ting to note is that \(T_{\eta,s}(x)\) has a slope less than 1 and crosses the \(45^\circ\) line at \(s\). This means that \(T_{\eta,s}(x)\) contracts mass around \(s\). Further, observe that \(T_{\eta,s}(x)\) is a straight line passing through \((s,s)\). Thus increasing \(s\) to \(s'\) will course \(T_{\eta,s}(x)\) to shift up, so the line passes through \((s',s')\). Hence the notation of ``more accurate signal'' can be interpreted as one signal \(X^{\eta'}\) being more correlated with the random state \(s\) than another signal \(X^\eta\), and the function \(T_{\eta,s}(x)\) imposes this additional correlation.
\end{example}
%=======================================================%

An illustrative example can also be given by applying \cref{eq:acuracy tranformation} to hypothesis testing.

%========== EXAMPLE: T-transformation 2==========%
\begin{example}\label{ex:t-transformation-2}
Consider the case where \(s\) can take two values \(s_{1}<s_{2}\). Let \(X^{\eta}\) be a information structure affiliated with \(S\). The optimal test based on \(X^{\eta}\) is given by the rejection region \(X^{\eta}>x^{*}\)  such that \(s_{1}\) is rejected in favor of \(s_{2}\) when \(X^{\eta}>x^{*}\). The probability of a type I error is then \(\mathbb{P}(X^{\eta}\le x^{*})=F(x^{*}\mid s_{2})\) and the probability of a type II error is \(1-F(x^{*}\mid s_{1})\). Now given that \(X^{\eta'}\) is more accurate than \(X^{\eta}\) is is possible to design a test with the same probability of type I error, by choosing \(x^{**}\) such that \(F(x^{**}\mid s_{2})=F(x^{*}\mid s_{2})\) (e.i. \ accept \(s_{2}\) if \(X^{\eta}\ge x^{**}\) . However, since \(X^{\eta'}\) is more accurate than \(X^{\eta}\)  then \(x^{**}\ge F^{\eta'^{-1}}(F^{\eta}(x\mid s_{1})\mid s_{1})\). As \(x^{**}\) lies on or, to the right of \(x^{*}\) then the test based on \(X^{\eta'}\) is a least as powerful as the test based on \(X^{\eta}\) \citep{Lehmann1988,Persico2000}.\footnote{For a graphical example, see \cref{app:test-power}}
\end{example}
%=====================================================%

%%--------------------------------------------------------------------------
%% Subsection: Demand for information
%%--------------------------------------------------------------------------

\subsection{Demand for information}

Given that we now know, when a test can be considered more informative than another, I can know turn to the problem of informativeness. To use the notation of informativeness I make two assumptions

%==========  ASSUMPTION: needed for proof  ==========%
\begin{assumption}
	The utility function is differential in \(t\) and the optimal solution \(t^*(x)\) is differentiable in in \(\eta\) and \(x\)
\end{assumption}
\begin{assumption}
	For all pairs of signals and states \((s,x)\) the CDF \(G^\eta(s\mid x)\) is differentiable in \(\eta\) on \(E\) and is continuous in \(s\)
\end{assumption}
%====================================================%

%========== THEOREM: informative ==========%
\begin{theorem}\label{thm:informative}
\parencite{Persico2000}
Suppose that \(X^{\eta}\) and \(X^{\eta'}\) are affiliated with \(S\) and that \(\left \{X^{\eta}\right \} _{\eta\in E}\) is A-ordered, such that \(X^{\eta'}\) is more accurate than \(X^{\eta}\). Then for all utility functions with a single crossing property, \(X^{\eta'}\) is more informative than \(X^{\eta}\)
\end{theorem}
% the real important fact here is that u is monotonically increasing in s
\begin{proof}
See \citet{Lehmann1988} section 4 and \citet{Karlin1956} Lemma 3--4 and theorem 1.
\end{proof}
%=============================================%

It follows directly from \cref{thm:informative} that when \(X^{\eta'}\) is more informative than \(X^{\eta}\)  then
\begin{align}
	\label{eq:utility-increasing-information}
	\begin{split}
	\int_{X}\int_{S}u(t,s)\dif G^{\eta'}(s\mid x)\dif F(x)&\geq \int_{X}\int_{S}u(t,s)\dif G^{\eta}(s\mid x)\, dF(x) \Leftrightarrow \\
	U(t,s;\eta')&\geq U(s,t;\eta)
\end{split}
\end{align}

From the above equation, it is clear that the patient will always prefer a more accurate signal to a less accurate signal.

\textcite{Persico2000} goes on to show that when \(u(t,s)\) is risk-sensitive increasing in \(s\), then the marginal value of information
\begin{align}
		MR(\eta)=\frac{\partial}{\partial \eta} \int_{X}\int_{S}u(t,s)\dif G^{\eta}(s\mid x)\dif F(x) \label{eq:marginal-value-of-information}
\end{align}


is increasing in \(s\).

From \cref{eq:marginal-value-of-information} it follows straight forward that the optimal level of accuracies defined by
\begin{align}
	MR(\eta)-C(\eta)=0
\end{align}
 is increasing in \(s\), where \(C(\eta)\) is the cost of obtaining the signal \(X^\eta\). In all of this paper it will be assumed that the cost of signal acquisition is increasing in \(\eta\), such that more accurate signals are more costly. The intuition is that when the risk sensitivity increases, information becomes more valuable.
%%--------------------------------------------------------------------------
%% Information aggregation and ordering over time
%%--------------------------------------------------------------------------

\subsection{Information Aggregation and Ordering Over Time}
i now turn to the problem of aggregating information over time. The question is, if the physician receives a signal \(x_1\) in period 1 and \(x_2\) in period 2, when will the aggregation of the two signals overt time then be better than just one of them? Stated more formally, when will \(MR(\eta(i))\) be increasing in time \(i\)?

\begin{lemma}\label{lem:produc-affiliation}
	if \(g(\cdot)\) and \(h(\cdot)\) are affiliated and non-negative, then \(f(\cdot)=g(\cdot)h(\cdot)\) is also affiliated.
\end{lemma}
\begin{proof}
	See \textcite{Milgrom1982a}
\end{proof}
A consequence of \cref{lem:produc-affiliation} is that the posterior of a density will be affiliated if both the prior and the likelihood function are affiliated.

\begin{example}
 Assume that in the first period, the agent receives a signal \(x_1\) and forms the posterior \(h(s\mid x_1)\) where \(x_1,s\) is affiliated. In the second period the agent receives a new signal \(x_2\). \Cref{lem:produc-affiliation} then says that the posterior \(f(s\mid x_2,x_1) \propto h(s\mid x_1)g(x_2\mid x_1,s)\) is affiliated, if \(x_2,s\) is also affiliated.
 \end{example}

\Cref{lem:produc-affiliation} is needed to guarantee that the optimal treatment is still an increasing function of the signal, even after updating, such that \(t^*(x_i)\) is increasing in \(x_i\).

I now turn to the problem of ordering information over time. Let \(\eta(i)\) be the information order at time \(i\) after receiving \({X}^{\eta(i)}=X^{1},\ldots,X^{i}\) signals. It is still assumed that \(\{{X}^{\eta(i)}\}_{\eta(i)\in E}\) and that higher \(\eta(i)\) implies higher accuracy.

The question is then, under which conditions the expected utility of the patient is increasing in time. But first I introduce a technical lemma by \textcite{Persico1996} and one assumption that will be used in the proof

\begin{lemma}\label{lem:optimal-condition-lemma}
    Let \([a,b]\) be in interval on \(\mathbb{R}\). Let \(J(\cdot)\) be a nondecreasing real function and \(H(\cdot)\) be a quasi monotone increasing real function. Assume that for some measure \(\mu\in\mathbb{R}\) it holds that
	\begin{align}
	\int_a^b H(s)\, d\mu(s)=0\label{eq:optimal-condition-lemma}
	\end{align}
   then
   \[
    	\int_a^b H(s)J(s)\dif \mu(s)\ge0
   \]

\end{lemma}
\begin{proof}
	Because of \cref{eq:optimal-condition-lemma} and the fact the \(H(\cdot)\) is quasi-monotone there must be a part on \(s_0\in[a,b]\) before which \(H\) is non-positive and after which is it non-negative. Let \(\bar{J}=J(s)-J(s_0)\): because \(J\) is non-decreasing, \(\bar{J}\) non-positive before \(s_0\) and non-negative after. I can then write
	\[
		\int_a^b H(s)J(s)\, d\mu(s)=\int_a^b H(s)\bar{J}(s)\dif \mu(s)
	\]
because of \cref{eq:optimal-condition-lemma}. Rewriting the rhs the above to
\[
	\int_a^{s_0} H(s)\bar{J}(s)\dif \mu(s)+ \int_{s_0}^b H(s)\bar{J}(s)\dif \mu(s)\geq 0
\]
because of the fact that \(H(\cdot)\) and \(\bar{J}(\cdot)\) have the same sign on \([a,s_0]\) and \([s_0,b]\)
\end{proof}

\begin{assumption}
	\(i\) is a continues real variable and \(\eta(i)\) is continuous and differential in \(i\)
\end{assumption}

\begin{theorem}\label{thm:mri}
For a A-ordered family of signals the \(MR(i)\geq0\) iff (i) the T-transformation function \(T_{\eta(i),s}\) is increasing in \(i\) (ii) a decision rule \(t^\eta(i)(x)\) is quasi-monotone in the accuracy-order, such that higher A-order cannot lead to a decreasing \(t^\eta(i)(x)\)
\end{theorem}
\begin{proof}
I want to show that
\[
	\pder{i}\int_X\int_S u(s,t^{\eta(i)}(x))\dif G^{\eta(i)}\dif F(x)\geq0
\]
Given the definition of the T-function, I can write the above as
\[
	\pder{i}\int_X\int_S u(s,t^{\eta(i)}(T_{\eta(i),s}(x)))\dif G^{\eta(i-1)}\dif F(x)
\]
as the T-function transform the signal from the previous period in to the signal in this period.

The envelope theorem states that I can ignore the differentiation of the optimal treatment wrt. \(i\). The inner integral can the be written as
\[
	\int_S \left[\pder{t}u(t^{\eta(i)}(T_{\eta(i),s}(x)))\right]\pder{\eta(i)}t^{\eta(i)}(x)\pder{i}T_{\eta(i),s}(x)\dif G^{\eta(i-1)}
\]
However the first-order-condition says that
\[
	\int_S \left[\pder{t}u(t^{\eta(i)}(T_{\eta(i),s}(x)))\right]\pder{\eta(i)}t^{\eta(i)}(x)\dif G^{\eta(i-1)}=0
\]

The term \(\left[\pder{t}u(t^{\eta(i)}(T_{\eta(i),s}(x)))\right]\) is quasi-monotone by the fact that it has a single crossing property. \textcite{Quah2009} discuss in proposition 9, under which circumstances and increasing decision rule under the signal \(\eta\) is also increasing under \(\eta'\). If this is the case, then the term \(\pder{\eta(i)}t^{\eta(i)}(x)\) is also quasi-monotone. Thus the first part of the integral is quasi-monotone. If \(\pder{i}T_{\eta(i),s}(x)\) is a non-decreasing function then \(MR(i)\geq0\) by \cref{lem:optimal-condition-lemma}.
\end{proof}
The intuition behind \cref{thm:mri}, is that the T-function transforms add correlation between the state \(s\) and the signal \(x\) only when \(T_{\eta(i),s}\) is an increasing function.
%%--------------------------------------------------------------------------
%% Section: The physician problem
%%--------------------------------------------------------------------------

\section{The physician problem}
\todo{From here, it is very preliminary work in progress.}
The physician has a utility function given by
\[
	V=v(M,\eta)
\]
where the physicians payment, \(M\) is given by
\[
	M=\delta+(p-\omega)q
\]
where \(\delta\) is a fixed payment, \(p\) is the physician payment per unit of treatment, \(q\) is quantity of treatment.

I also assume that the physician can increase the quality of treatment by increasing the diagnosis accuracy through effort, such that \(\eta\) increases when more effort is applied. Where \(\eta\) is the level of accuracy in \(X^\eta\). The cost of accuracy is given by \(C\). Assuming a separable utility function, the physician problem can be expressed as
\[
	v(M,e)=M-C(\eta)
\]
As the subject of this paper, is the acquisition of information, through physician effort, I ignore the treatment decision and assume for simplicity that the payment for treatment \(p\) can be set exactly equal to the cost \(\omega\)  The problem then simplifies to
\begin{align}
v(\delta,\eta)=\delta-C(\eta)\label{eq:phys-utility}
\end{align}
Further, the physician will only apply effort as long as \cref{eq:phys-utility} is positive. Let \(\bar{\eta}\) be the solution to \(\delta=C(\eta)\). Then \(\bar{\eta}\) must be between \([0,\bar{\eta}]\).

If I let \(\lambda\in[0,1]\) be the physician preference for effort we can restate the physicians problem in \cref{eq:phys-utility} as
\begin{align}
 	 v(\delta,\lambda,\bar{\eta})=\delta-C(\lambda\bar{\eta})\label{eq:phys-utility2}
\end{align}

%%--------------------------------------------------------------------------
%% Section: The patients search for treatment in a static setting
%%--------------------------------------------------------------------------
\section{The patients search for the best treatment}

From \cref{eq:utility-increasing-information} it is clear that the patient will always prefer more information to less information. Given the definition of information aggregation, the question is for which values of \(\dot{\eta}_i\) the patients utility is increasing.

%==========  DEFINITION: Accuracy order in i  ==========%
\begin{definition}\label{def:i-accuracy-order}
	The accuracy order is increasing in \(i\) iff \(\dot{\eta}_i=\partial^2 \big/\partial \eta \partial i>0\)
\end{definition}
%=========================================================%
 Given \cref{def:i-accuracy-order} and~\cref{thm:informative} is is clear that the patients expected utility is increasing in \(i\) only if the physician accumulates information over time, in such a way that the information order is increasing.

 \begin{lemma}\label{lem:increasing-utilitiy-i}
 	If the accuracy order is increasing in \(i\) then the expected utility function has increasing differences in \(s,i\)
 \end{lemma}
 \begin{proof}
  	As \(\eta\) increases in \(i\) it is enough to show that \(\eta\) is increasing in \(s\). This follows directly from~\cref{eq:marginal-value-of-information}
 \end{proof}

 The intuition behind \cref{lem:increasing-utilitiy-i} is the as the risk sensitivity is increasing in \(s\), then form higher values of \(s\) information is more valuable. As more information is aggregated over time, then a patient with higher \(s\) benefits more from a higher \(i\) than a patient with a lower \(s\).
%%--------------------------------------------------------------------------
%% Dynamic Settings
%%--------------------------------------------------------------------------

\printbibliography%

%%--------------------------------------------------------------------------
%% Appendix
%%--------------------------------------------------------------------------

\begin{appendices}
\section{Appendix}\label{sec:appendix}
\subsection{More informative \& least as powerful test}\label{app:test-power}

See~\cref{fig:test-power}

\begin{figure}[!ht]
	\centering
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{test-power-1.pdf}
		\caption{}\label{fig:test-power-1}
	\end{subfigure}
	\begin{subfigure}[b]{\textwidth}
		\includegraphics[width=\textwidth]{test-power-2.pdf}
		\caption{}\label{fig:test-power-2}
	\end{subfigure}
\caption{The blue shaded area is the probability of a type I error, and the red shaded area is the test power, while the non-shaded area under the red curve is the probability of a type II error. \Cref{fig:test-power-1,fig:test-power-2} have the same probability of a type I error, but the power of the test in \cref{fig:test-power-2} is higher than in \cref{fig:test-power-2}, as the probability of a type II error is smaller}\label{fig:test-power}
\end{figure}

%%--------------------------------------------------------------------------
%% Appendix: Stochastic Affiliation
%%--------------------------------------------------------------------------

\subsection{Stochastic Affiliation}\label{app:affiliation}
\begin{definition}
	The random variables \(X_1,\ldots,X_n\) are said to be affiliated if their joint PDF \(f(\mathbf{x})\) is log-supermodular, meaning that for  all \(\mathbf{x},\mathbf{x}'\in\mathbb{R}_nb\), we have
	\[
		f(\mathbf{x}\land \mathbf{x}')f(\mathbf{x}\lor \mathbf{x}')\geq f(\mathbf{x})f(\mathbf{x}')
	\]
When \(f\) is twice continuously differentiable, then equivalently \(bX_1,\ldots,X_n\) are affiliated iff for all \(i\ne j\)
\[
	\frac{\partial^2}{\partial x_i \partial x_j}\ln f\geq 0
\]
\end{definition}
Consider two joint random variables \(X\) and \(S\). Affiliation then tells us about the conditional distribution of \(f(S\mid x)\). If \(x\leq x', y\leq y'\), then affiliation implies that
\[
	\frac{f(x,y')}{f(x,y)}\leq \frac{f(x',y')}{f(x',y)}
\]
which we can rewrite as
\[
	\frac{f(y'\mid x)f_X(x)}{f(y\mid x)f_X(x)}=\frac{f(y'\mid x)}{f(y\mid x)}\leq \frac{f(y'\mid x')}{f(y\mid x')} = \frac{f(y'\mid x')f_X(x')}{f(y\mid x')f_X(x')}
\]
which tells us the that likelihood ratio \(f(\cdot\mid x)\big/ f(\cdot\mid x)\) is increasing in \(x\) and thereby displays the monotone likelihood ratio property, which implies first-order (and hence second-order) stochastic dominance. \cite[in proposition 8 and 10 ]{Quah2009}, proofs that the monotone likelihood ratio property is required for the family of functions with the single-crossing property to have an increasing optimal solution in the signal \(x\).

A further property of affiliation is that it is preserved under Bayesian updating, such that if the prior \(f(s')\big/f(s),\, s'\geq s\) has a monotone likelihood ratio property, then the posterior \(f(s'\mid x)\big/f(s\mid x)\) also have the monotone likelihood ratio property for any likelihood function \(f(x\mid \cdot)\).

At last, affiliation is also preserved under multiplication, such that if \(f(\mathbf{x})=h(\mathbf{x})g(\mathbf{x})\), where \(g\) and \(h\) is nonnegative and affiliated, then \(f\) is also affiliated.
%%--------------------------------------------------------------------------
%% Appendix: Proof Topiks
%%--------------------------------------------------------------------------

\subsection[A simplified proof of Topkisâ€™s Monotonicity Theorem is]{A simplified proof of \Citeauthor{Topkis1998}'s Monotonicity Theorem}\label{app:topiks-proof}
\begin{theorem}
	Consider the problem
	\[
		t^*(s)=\argmax_{s\in S} u(t,s)
	\]
	where \(T,S\in \mathbb{R}\) and \(T_s\subset T\) is the correspondence from \(S\) to \(T\)  with \(T_s\) being the set of feasible treatments, when the diseases is \(s\).  Assume also that (i) \(u\) has increasing differences in \((t,s)\)  and (ii) \(T_s=[g(s),h(s)]\)  where \(h,g:S \rightarrow \mathbb{R}\) are increasing functions with \(g\leq h\).  Then the optimal solution \(t^*(s)\) is an increasing function.
\end{theorem}

\begin{proof}
	The proof is done by contradiction. Assume that \(t^*(s)\) is not increasing. Then for some \(s'>s\)  \(t^*(s')<t^*(s)\).  Then using assumption (ii) and the fact that \(t^*(s)\in T_s\)  and \(t^*(s')\in T_{s'}\)  it follows that \(g(s)\leq g(s')\leq t^*(s') < t^*(s) \leq h(s) \leq h(s')\)  so that \(t^*(s)\in T_{s'}\) and \(t^*(s')\in T_s\).  Using the latter facts along with \(t^*(s)\in t(s)\) and \(t^*(s')\in t(s')\)  we have
	\[
		0\geq u[s',t^*(s)]-u[s',t^*(s')]\geq u[s,t^*(s)]-u[s,t^*(s')]\geq 0,
	\]
	which holds throughout. Hence, \(t^*(s)\in t(s')\) is a contradiction to the fact that \(t^*(s')=\max \{t(s')\}\) since \(t^*(s')<t^*(s)\).  Hence, \(t^*(s)\) is an increasing function \parencite{Amir2005}.\footnote{In this proof, it is assumed that \(T_s\cap T_{s'}\ne \emptyset\). If this was the case, one would trivially have that \(t^*(s)<t^*(s')\) }
\end{proof}
\end{appendices}
\end{document}